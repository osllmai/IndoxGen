{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:22:25.538038Z",
     "start_time": "2024-09-18T10:22:25.517529Z"
    }
   },
   "cell_type": "code",
   "source": "nv_api_key = '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'",
   "id": "66f702a44f900afb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T14:02:10.279352Z",
     "start_time": "2024-09-17T14:02:06.954003Z"
    },
    "id": "771c069197fa82e9"
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from typing import List, Dict, Any, Callable\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class SyntheticDataGenerator:\n",
    "    def __init__(self, api_key: str, num_samples: int = 1, temperature: float = 0.2, top_p: float = 0.7, max_tokens: int = 2048):\n",
    "        \"\"\"\n",
    "        Initializes the synthetic data generator with necessary configurations for NVIDIA Nemotron API.\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.num_samples = num_samples\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.max_tokens = max_tokens\n",
    "        self.base_url = \"https://integrate.api.nvidia.com/v1\"  # NVIDIA API endpoint\n",
    "\n",
    "    def generate_data(self, subject: str, extra: str, runs: int, prompt_template: Callable[[str, str, int], str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Generate synthetic data based on the given instructions using a prompt template.\n",
    "        \"\"\"\n",
    "        synthetic_results = []\n",
    "        for _ in range(runs):\n",
    "            prompt = prompt_template(subject, extra, self.num_samples)\n",
    "\n",
    "            # Prepare the API call\n",
    "            data = {\n",
    "                \"model\": \"nvidia/nemotron-4-340b-instruct\",\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"temperature\": self.temperature,\n",
    "                \"top_p\": self.top_p,\n",
    "                \"max_tokens\": self.max_tokens,\n",
    "                \"stream\": False\n",
    "            }\n",
    "\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "            }\n",
    "\n",
    "            # Make the API call to NVIDIA's endpoint\n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/chat/completions\",\n",
    "                headers=headers,\n",
    "                json=data\n",
    "            )\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                raise ValueError(f\"Failed to call the API: {response.status_code} {response.text}\")\n",
    "\n",
    "            # Get the raw response from the model\n",
    "            raw_output = response.json()['choices'][0]['message']['content']\n",
    "\n",
    "            # Parse the response and add it to synthetic results\n",
    "            parsed_data = self._parse_response(raw_output)\n",
    "            synthetic_results.append(parsed_data)\n",
    "\n",
    "        return synthetic_results\n",
    "\n",
    "    def _parse_response(self, raw_output: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Parse the raw LLM output into a structured format. Strips extra data and\n",
    "        ensures that only valid JSON content is returned.\n",
    "\n",
    "        :param raw_output: The raw string response from the model\n",
    "        :return: Parsed JSON as a list of dictionaries\n",
    "        \"\"\"\n",
    "        # Remove any potential code block delimiters\n",
    "        json_output = raw_output.strip().strip('```json').strip('```').strip()\n",
    "\n",
    "        # Find the first valid JSON object in the response\n",
    "        try:\n",
    "            # Sometimes the model may return multiple chunks of text; we split by braces.\n",
    "            json_output = json_output[json_output.find('{'):json_output.rfind('}')+1]\n",
    "            # Try to parse the cleaned-up output as JSON\n",
    "            return json.loads(json_output)\n",
    "        except json.JSONDecodeError as e:\n",
    "            # Handle parsing errors and provide feedback\n",
    "            raise ValueError(f\"LLM output is not valid JSON: {e}\\nRaw output: {raw_output}\")\n",
    "\n",
    "\n"
   ],
   "id": "771c069197fa82e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T14:02:10.992535Z",
     "start_time": "2024-09-17T14:02:10.294Z"
    },
    "id": "86a69a0a7fcd4025"
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# Define a MedicalBilling class for structured data\n",
    "class MedicalBilling(BaseModel):\n",
    "    patient_id: str\n",
    "    patient_name: str\n",
    "    diagnosis_code: str\n",
    "    procedure_code: str\n",
    "    total_charge: float\n",
    "    insurance_claim_amount: float\n"
   ],
   "id": "86a69a0a7fcd4025",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T14:02:11.016893Z",
     "start_time": "2024-09-17T14:02:10.999750Z"
    },
    "id": "c9ea1589de162b4d"
   },
   "cell_type": "code",
   "source": [
    "def my_prompt_template(subject: str, extra: str, num_samples: int) -> str:\n",
    "    return (\n",
    "        f\"Generate {num_samples} samples of {subject} data. Ensure the following fields are present: \"\n",
    "        f\"Patient ID, Patient Name, Diagnosis Code, Procedure Code, Total Charge, Insurance Claim Amount. \"\n",
    "        f\"{extra} Output the data in valid JSON format.\"\n",
    "    )\n"
   ],
   "id": "c9ea1589de162b4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T14:02:24.493597Z",
     "start_time": "2024-09-17T14:02:11.021907Z"
    },
    "id": "43836bf33c8c985c",
    "outputId": "64a0f6c8-5728-444a-c9ff-5ead19c31abf"
   },
   "cell_type": "code",
   "source": [
    "# Initialize the synthetic data generator\n",
    "api_key = nv_api_key\n",
    "generator = SyntheticDataGenerator(api_key=api_key, num_samples=1)\n",
    "\n",
    "# Define the instructions for synthetic data generation\n",
    "subject = \"medical_billing\"\n",
    "extra = \"The name must be chosen at random. Make it something unusual.\"\n",
    "runs = 1\n",
    "\n",
    "# Generate the synthetic data using the custom prompt template\n",
    "synthetic_results = generator.generate_data(subject=subject, extra=extra, runs=runs, prompt_template=my_prompt_template)\n",
    "synthetic_results"
   ],
   "id": "43836bf33c8c985c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'medical_billing_data': {'Patient ID': 'P12345',\n",
       "   'Patient Name': 'Zephyr Quicksilver',\n",
       "   'Diagnosis Code': 'M54.5',\n",
       "   'Procedure Code': '99213',\n",
       "   'Total Charge': 150.0,\n",
       "   'Insurance Claim Amount': 120.0}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T14:02:41.508935Z",
     "start_time": "2024-09-17T14:02:41.473120Z"
    },
    "id": "83b60b855b243183",
    "outputId": "6c03510f-6a4a-476b-ec53-273441f0f450"
   },
   "cell_type": "code",
   "source": [
    "# Convert the synthetic results into structured MedicalBilling objects\n",
    "synthetic_data = []\n",
    "for result in synthetic_results:\n",
    "    # Check if the result is a dictionary and contains 'medical_billing_data'\n",
    "    if isinstance(result, dict) and 'medical_billing_data' in result:\n",
    "        entry = result['medical_billing_data']\n",
    "        # Now process the entry dictionary\n",
    "        billing_data = MedicalBilling(\n",
    "            patient_id=entry['Patient ID'],  # Adjusted to match the correct key name\n",
    "            patient_name=entry['Patient Name'],\n",
    "            diagnosis_code=entry['Diagnosis Code'],\n",
    "            procedure_code=entry['Procedure Code'],\n",
    "            total_charge=float(entry['Total Charge']),\n",
    "            insurance_claim_amount=float(entry['Insurance Claim Amount'])\n",
    "        )\n",
    "        synthetic_data.append(billing_data)\n",
    "    else:\n",
    "        print(f\"Unexpected result format: {result}\")\n",
    "\n",
    "# Convert the synthetic data to a Pandas DataFrame\n",
    "synthetic_df = pd.DataFrame([billing.dict() for billing in synthetic_data])\n",
    "\n",
    "# Display the DataFrame\n",
    "synthetic_df\n"
   ],
   "id": "83b60b855b243183",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient_id        patient_name diagnosis_code procedure_code  total_charge  \\\n",
       "0     P12345  Zephyr Quicksilver          M54.5          99213         150.0   \n",
       "\n",
       "   insurance_claim_amount  \n",
       "0                   120.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>patient_name</th>\n",
       "      <th>diagnosis_code</th>\n",
       "      <th>procedure_code</th>\n",
       "      <th>total_charge</th>\n",
       "      <th>insurance_claim_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P12345</td>\n",
       "      <td>Zephyr Quicksilver</td>\n",
       "      <td>M54.5</td>\n",
       "      <td>99213</td>\n",
       "      <td>150.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "a680f230e9f06e3e",
    "ExecuteTime": {
     "end_time": "2024-09-18T10:21:54.223458Z",
     "start_time": "2024-09-18T10:21:50.825795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from typing import List, Dict, Any, Callable\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class SyntheticDataGenerator:\n",
    "    def __init__(self, api_key: str, num_samples: int = 1, temperature: float = 0.2, top_p: float = 0.7, max_tokens: int = 2048):\n",
    "        \"\"\"\n",
    "        Initializes the synthetic data generator with necessary configurations for NVIDIA Nemotron API.\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.num_samples = num_samples\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.max_tokens = max_tokens\n",
    "        self.base_url = \"https://integrate.api.nvidia.com/v1\"  # NVIDIA API endpoint\n",
    "\n",
    "    def generate_data(self, subject: str, extra: str, runs: int, examples: List[Dict[str, str]], prompt_template: Callable[[str, str, List[Dict[str, str]], int], str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Generate synthetic data based on the given instructions using a prompt template and examples.\n",
    "        \"\"\"\n",
    "        synthetic_results = []\n",
    "        for _ in range(runs):\n",
    "            prompt = prompt_template(subject, extra, examples, self.num_samples)\n",
    "\n",
    "            # Prepare the API call\n",
    "            data = {\n",
    "                \"model\": \"nvidia/nemotron-4-340b-instruct\",\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"temperature\": self.temperature,\n",
    "                \"top_p\": self.top_p,\n",
    "                \"max_tokens\": self.max_tokens,\n",
    "                \"stream\": False\n",
    "            }\n",
    "\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "            }\n",
    "\n",
    "            # Make the API call to NVIDIA's endpoint\n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/chat/completions\",\n",
    "                headers=headers,\n",
    "                json=data\n",
    "            )\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                raise ValueError(f\"Failed to call the API: {response.status_code} {response.text}\")\n",
    "\n",
    "            # Get the raw response from the model\n",
    "            raw_output = response.json()['choices'][0]['message']['content']\n",
    "\n",
    "            # Parse the response and add it to synthetic results\n",
    "            parsed_data = self._parse_response(raw_output)\n",
    "            synthetic_results.append(parsed_data)\n",
    "\n",
    "        return synthetic_results\n",
    "\n",
    "    def _parse_response(self, raw_output: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Parse the raw LLM output into a structured format. Strips extra data and\n",
    "        ensures that only valid JSON content is returned.\n",
    "        \"\"\"\n",
    "        # Remove any potential code block delimiters\n",
    "        json_output = raw_output.strip().strip('```json').strip('```').strip()\n",
    "\n",
    "        # Find the first valid JSON object in the response\n",
    "        try:\n",
    "            # Sometimes the model may return multiple chunks of text; we split by braces.\n",
    "            json_output = json_output[json_output.find('{'):json_output.rfind('}')+1]\n",
    "            # Try to parse the cleaned-up output as JSON\n",
    "            return json.loads(json_output)\n",
    "        except json.JSONDecodeError as e:\n",
    "            # Handle parsing errors and provide feedback\n",
    "            raise ValueError(f\"LLM output is not valid JSON: {e}\\nRaw output: {raw_output}\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "a680f230e9f06e3e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:21:54.663744Z",
     "start_time": "2024-09-18T10:21:54.223458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# Define a MedicalBilling class for structured data\n",
    "class MedicalBilling(BaseModel):\n",
    "    patient_id: str\n",
    "    patient_name: str\n",
    "    diagnosis_code: str\n",
    "    procedure_code: str\n",
    "    total_charge: float\n",
    "    insurance_claim_amount: float"
   ],
   "id": "600fa2160d43036d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:21:56.250437Z",
     "start_time": "2024-09-18T10:21:56.231025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "def my_prompt_template(subject: str, extra: str, examples: List[Dict[str, str]], num_samples: int) -> str:\n",
    "    \"\"\"\n",
    "    Creates a prompt with few-shot examples and a template for generating new synthetic data.\n",
    "    \"\"\"\n",
    "    example_text = \"\\n\".join([f\"Example:\\n{ex['example']}\" for ex in examples])\n",
    "    \n",
    "    prompt = (\n",
    "        f\"{example_text}\\n\\n\"\n",
    "        f\"Now generate {num_samples} samples of {subject} data. Ensure the following fields are present: \"\n",
    "        f\"Patient ID, Patient Name, Diagnosis Code, Procedure Code, Total Charge, Insurance Claim Amount. \"\n",
    "        f\"{extra} Output the data in valid JSON format.\"\n",
    "    )\n",
    "    return prompt"
   ],
   "id": "30a9ce418ab359a1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:22:00.199214Z",
     "start_time": "2024-09-18T10:22:00.182182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the examples for few-shot learning\n",
    "examples = [\n",
    "    {\n",
    "        \"example\": \"\"\"Patient ID: 123456, Patient Name: John Doe, Diagnosis Code: \n",
    "        J20.9, Procedure Code: 99203, Total Charge: $500, Insurance Claim Amount: $350\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"example\": \"\"\"Patient ID: 789012, Patient Name: Johnson Smith, Diagnosis \n",
    "        Code: M54.5, Procedure Code: 99213, Total Charge: $150, Insurance Claim Amount: $120\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"example\": \"\"\"Patient ID: 345678, Patient Name: Emily Stone, Diagnosis Code: \n",
    "        E11.9, Procedure Code: 99214, Total Charge: $300, Insurance Claim Amount: $250\"\"\"\n",
    "    },\n",
    "]\n"
   ],
   "id": "41894fef4ef2ae93",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:22:53.587329Z",
     "start_time": "2024-09-18T10:22:45.656993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the synthetic data generator\n",
    "api_key = nv_api_key\n",
    "generator = SyntheticDataGenerator(api_key=api_key, num_samples=1)\n",
    "\n",
    "# Define the instructions for synthetic data generation\n",
    "subject = \"medical_billing\"\n",
    "extra = \"The name must be chosen at random. Make it something unusual.\"\n",
    "runs = 1\n",
    "\n",
    "# Generate the synthetic data using the custom prompt template with examples\n",
    "synthetic_results = generator.generate_data(subject=subject, extra=extra, runs=runs, examples=examples, prompt_template=my_prompt_template)"
   ],
   "id": "605462b3c1192c85",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:22:59.613537Z",
     "start_time": "2024-09-18T10:22:59.537544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the synthetic results into structured MedicalBilling objects\n",
    "synthetic_data = []\n",
    "for result in synthetic_results:\n",
    "    # Check if the result is a dictionary and contains 'medical_billing_data'\n",
    "    if isinstance(result, dict) and 'medical_billing_data' in result:\n",
    "        entry = result['medical_billing_data']\n",
    "        # Now process the entry dictionary\n",
    "        billing_data = MedicalBilling(\n",
    "            patient_id=entry['Patient ID'],  # Adjusted to match the correct key name\n",
    "            patient_name=entry['Patient Name'],\n",
    "            diagnosis_code=entry['Diagnosis Code'],\n",
    "            procedure_code=entry['Procedure Code'],\n",
    "            total_charge=float(entry['Total Charge']),\n",
    "            insurance_claim_amount=float(entry['Insurance Claim Amount'])\n",
    "        )\n",
    "        synthetic_data.append(billing_data)\n",
    "    else:\n",
    "        print(f\"Unexpected result format: {result}\")\n",
    "\n",
    "# Convert the synthetic data to a Pandas DataFrame\n",
    "synthetic_df = pd.DataFrame([billing.dict() for billing in synthetic_data])\n",
    "\n",
    "# Display the DataFrame\n",
    "synthetic_df"
   ],
   "id": "d2812cd7a7c7afb7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient_id        patient_name diagnosis_code procedure_code  total_charge  \\\n",
       "0     987654  Zephyr Quicksilver         G47.33          99215         450.0   \n",
       "\n",
       "   insurance_claim_amount  \n",
       "0                   320.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>patient_name</th>\n",
       "      <th>diagnosis_code</th>\n",
       "      <th>procedure_code</th>\n",
       "      <th>total_charge</th>\n",
       "      <th>insurance_claim_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>987654</td>\n",
       "      <td>Zephyr Quicksilver</td>\n",
       "      <td>G47.33</td>\n",
       "      <td>99215</td>\n",
       "      <td>450.0</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:17:13.993407Z",
     "start_time": "2024-09-18T16:17:13.914356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "from typing import Any, Dict, List, Optional, Callable, Union\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "class LLMChain:\n",
    "    \"\"\"Chain to handle LLM and prompt interaction.\"\"\"\n",
    "    def __init__(self, llm: Callable, prompt: Callable):\n",
    "        self.llm = llm\n",
    "        self.prompt = prompt\n",
    "\n",
    "    def run(self, subject: str, extra: str = \"\", examples: List[Dict[str, str]] = [], num_samples: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"Run the LLM chain and generate data based on inputs.\"\"\"\n",
    "        prompt_text = self.prompt(subject, extra, examples, num_samples)\n",
    "        synthetic_data = self.llm(prompt_text)\n",
    "        return synthetic_data\n",
    "\n",
    "    async def arun(self, subject: str, extra: str = \"\", examples: List[Dict[str, str]] = [], num_samples: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"Asynchronous run method.\"\"\"\n",
    "        prompt_text = self.prompt(subject, extra, examples, num_samples)\n",
    "        synthetic_data = await asyncio.to_thread(self.llm, prompt_text)  # Running LLM in a thread for async compatibility\n",
    "        return synthetic_data\n",
    "\n",
    "\n",
    "class SyntheticDataGenerator:\n",
    "    \"\"\"Generate synthetic data using an LLM and few-shot template, with dynamic example handling.\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, template: Callable, num_samples: int = 1, temperature: float = 0.2, top_p: float = 0.7, max_tokens: int = 2048):\n",
    "        \"\"\"Initialize the synthetic data generator.\"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.num_samples = num_samples\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.max_tokens = max_tokens\n",
    "        self.base_url = \"https://integrate.api.nvidia.com/v1\"  # NVIDIA API endpoint\n",
    "        \n",
    "        # Chain and example management\n",
    "        self.template = template\n",
    "        self.llm_chain = None\n",
    "        self.examples = []  # Initial empty list for few-shot examples\n",
    "\n",
    "    def set_llm_chain(self, llm: Callable):\n",
    "        \"\"\"Sets the LLM chain.\"\"\"\n",
    "        if not llm:\n",
    "            raise ValueError(\"LLM must be provided to initialize LLM chain.\")\n",
    "        self.llm_chain = LLMChain(llm=llm, prompt=self.template)\n",
    "\n",
    "    def generate_data(self, prompt: str) -> Dict[str, Any]:\n",
    "        \"\"\"Make an API call to the LLM.\"\"\"\n",
    "        data = {\n",
    "            \"model\": \"nvidia/nemotron-4-340b-instruct\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"top_p\": self.top_p,\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "        }\n",
    "\n",
    "        response = requests.post(f\"{self.base_url}/chat/completions\", headers=headers, json=data)\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"API error: {response.status_code} {response.text}\")\n",
    "\n",
    "        raw_output = response.json()['choices'][0]['message']['content']\n",
    "        return self._parse_response(raw_output)\n",
    "\n",
    "    def _parse_response(self, raw_output: str) -> Dict[str, Any]:\n",
    "        \"\"\"Parses the LLM response into JSON.\"\"\"\n",
    "        json_output = raw_output.strip().strip('```json').strip('```').strip()\n",
    "        json_output = json_output[json_output.find('{'):json_output.rfind('}')+1]\n",
    "        try:\n",
    "            return json.loads(json_output)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"LLM output is not valid JSON: {e}\")\n",
    "\n",
    "    def _update_examples(self, result: Dict[str, Any]) -> None:\n",
    "        \"\"\"Updates the few-shot examples with new generated data.\"\"\"\n",
    "        if len(self.examples) >= 3:  # Limit example pool to the last 3 results\n",
    "            self.examples.pop(0)\n",
    "        self.examples.append({\"example\": json.dumps(result)})  # Add new example\n",
    "\n",
    "    def generate(self, subject: str, runs: int, extra: str = \"\") -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generates synthetic data synchronously, updating examples dynamically.\"\"\"\n",
    "        if self.llm_chain is None:\n",
    "            raise ValueError(\"LLM chain is not set. Use 'set_llm_chain' to initialize the chain.\")\n",
    "        \n",
    "        results = []\n",
    "        for _ in range(runs):\n",
    "            result = self.llm_chain.run(subject=subject, extra=extra, examples=self.examples, num_samples=self.num_samples)\n",
    "            self._update_examples(result)  # Update examples with new result\n",
    "            results.append(result)\n",
    "        return results\n",
    "\n",
    "    async def agenerate(self, subject: str, runs: int, extra: str = \"\") -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generates synthetic data asynchronously, updating examples dynamically.\"\"\"\n",
    "        if self.llm_chain is None:\n",
    "            raise ValueError(\"LLM chain is not set. Use 'set_llm_chain' to initialize the chain.\")\n",
    "        \n",
    "        results = []\n",
    "        async def run_chain_async() -> None:\n",
    "            result = await self.llm_chain.arun(subject=subject, extra=extra, examples=self.examples, num_samples=self.num_samples)\n",
    "            self._update_examples(result)\n",
    "            results.append(result)\n",
    "\n",
    "        await asyncio.gather(*(run_chain_async() for _ in range(runs)))\n",
    "        return results\n",
    "\n",
    "\n",
    "class DatasetGenerator:\n",
    "    \"\"\"Generate synthetic datasets using a given LLM and prompt template.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: Callable, template: Callable, sentence_preferences: Optional[Dict[str, Any]] = None):\n",
    "        \"\"\"Initialize the dataset generator with an LLM and sentence preferences.\"\"\"\n",
    "        self.generator = SyntheticDataGenerator(api_key=\"\", template=template)\n",
    "        self.generator.set_llm_chain(llm)\n",
    "        self.sentence_preferences = sentence_preferences or {}\n",
    "\n",
    "    def generate_dataset(self, fields_collection: List[List[Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generate synthetic dataset synchronously.\"\"\"\n",
    "        results = []\n",
    "        for fields in fields_collection:\n",
    "            subject = fields[0] if fields else \"\"\n",
    "            extra = self.sentence_preferences.get(\"extra\", \"\")\n",
    "            runs = self.sentence_preferences.get(\"runs\", 1)\n",
    "            result = self.generator.generate(subject=subject, runs=runs, extra=extra)\n",
    "            results.extend(result)\n",
    "        return results\n",
    "\n",
    "    async def generate_dataset_async(self, fields_collection: List[List[Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generate synthetic dataset asynchronously.\"\"\"\n",
    "        results = []\n",
    "        async def run_async(fields):\n",
    "            subject = fields[0] if fields else \"\"\n",
    "            extra = self.sentence_preferences.get(\"extra\", \"\")\n",
    "            runs = self.sentence_preferences.get(\"runs\", 1)\n",
    "            result = await self.generator.agenerate(subject=subject, runs=runs, extra=extra)\n",
    "            results.extend(result)\n",
    "\n",
    "        await asyncio.gather(*(run_async(fields) for fields in fields_collection))\n",
    "        return results\n",
    "\n",
    "\n",
    "# Define the prompt template\n",
    "def my_prompt_template(subject: str, extra: str, examples: List[Dict[str, str]], num_samples: int) -> str:\n",
    "    \"\"\"Template to generate the LLM prompt using few-shot examples.\"\"\"\n",
    "    example_text = \"\\n\".join([f\"Example:\\n{ex['example']}\" for ex in examples])\n",
    "    prompt = (\n",
    "        f\"{example_text}\\n\\n\"\n",
    "        f\"Now generate {num_samples} samples of {subject} data. \"\n",
    "        f\"Ensure the following fields are present: Patient ID, Patient Name, Diagnosis Code, \"\n",
    "        f\"Procedure Code, Total Charge, Insurance Claim Amount. {extra} Output the data in valid JSON format.\"\n",
    "    )\n",
    "    return prompt\n"
   ],
   "id": "f5389de571bee6c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:17:57.212580Z",
     "start_time": "2024-09-18T16:17:34.819380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Usage example:\n",
    "api_key = nv_api_key  # Replace with your actual API key\n",
    "\n",
    "# Initialize the LLM (in this case the synthetic data generator's generate_data method)\n",
    "llm = SyntheticDataGenerator(api_key=api_key, template=my_prompt_template).generate_data\n",
    "\n",
    "# Create the dataset generator with LLM and preferences\n",
    "sentence_preferences = {\n",
    "    \"extra\": \"Ensure unusual patient names.\",\n",
    "    \"runs\": 2\n",
    "}\n",
    "\n",
    "dataset_generator = DatasetGenerator(llm=llm, template=my_prompt_template, sentence_preferences=sentence_preferences)\n",
    "\n",
    "# Generate dataset synchronously\n",
    "fields_collection = [[\"medical_billing\"]]\n",
    "synthetic_dataset = dataset_generator.generate_dataset(fields_collection)\n"
   ],
   "id": "a7995eee9d998c92",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:18:45.580023Z",
     "start_time": "2024-09-18T16:18:45.497796Z"
    }
   },
   "cell_type": "code",
   "source": "synthetic_dataset",
   "id": "b9200315d80313",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'medical_billing_data': [{'Patient ID': 'P12345',\n",
       "    'Patient Name': 'Xylophone Yonder',\n",
       "    'Diagnosis Code': 'M54.5',\n",
       "    'Procedure Code': '99213',\n",
       "    'Total Charge': 150.0,\n",
       "    'Insurance Claim Amount': 120.0}]},\n",
       " {'medical_billing_data': [{'Patient ID': 'P67890',\n",
       "    'Patient Name': 'Zephyr Zenith',\n",
       "    'Diagnosis Code': 'R10.1',\n",
       "    'Procedure Code': '99214',\n",
       "    'Total Charge': 200.0,\n",
       "    'Insurance Claim Amount': 160.0}]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:22:08.255560Z",
     "start_time": "2024-09-18T16:22:08.016099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flatten the synthetic dataset\n",
    "flattened_data = []\n",
    "\n",
    "for entry in synthetic_dataset:\n",
    "    if 'medical_billing_data' in entry:\n",
    "        for record in entry['medical_billing_data']:\n",
    "            flattened_data.append(record)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('synthetic_billing_data.csv', index=False)\n",
    "\n",
    "# Display the DataFrame (optional)\n",
    "print(df)"
   ],
   "id": "1a6e49ee1673c243",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient ID      Patient Name Diagnosis Code Procedure Code  Total Charge  \\\n",
      "0     P12345  Xylophone Yonder          M54.5          99213         150.0   \n",
      "1     P67890     Zephyr Zenith          R10.1          99214         200.0   \n",
      "\n",
      "   Insurance Claim Amount  \n",
      "0                   120.0  \n",
      "1                   160.0  \n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:27:26.743252Z",
     "start_time": "2024-09-18T16:27:18.134081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Asynchronous dataset generation\n",
    "async def generate_dataset_async():\n",
    "    async_synthetic_dataset = await dataset_generator.generate_dataset_async(fields_collection)\n",
    "    print(async_synthetic_dataset)\n",
    "\n",
    "# In Jupyter or environments with an active event loop\n",
    "# Use await directly to call the asynchronous function\n",
    "await generate_dataset_async()\n"
   ],
   "id": "878699eb63b12b2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'medical_billing_data': [{'Patient ID': 'P09876', 'Patient Name': 'Quirky Quasar', 'Diagnosis Code': 'G47.33', 'Procedure Code': '99215', 'Total Charge': 250.0, 'Insurance Claim Amount': 200.0}]}, {'medical_billing_data': [{'Patient ID': 'P09876', 'Patient Name': 'Quirky Quasar', 'Diagnosis Code': 'G47.33', 'Procedure Code': '99215', 'Total Charge': 250.0, 'Insurance Claim Amount': 200.0}]}]\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
